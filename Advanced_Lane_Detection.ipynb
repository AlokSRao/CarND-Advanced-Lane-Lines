{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The full pipeline for advanced lane recognition\n",
    "## by Alok Rao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import glob as glob\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Class to load all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters():\n",
    "    def BinaryImageThreshold(self, sobelThreshold, sChannelThreshold, redChannelThreshold, sobelKernelSize):\n",
    "        self.sobelThreshold = sobelThreshold\n",
    "        self.sChannelThreshold = sChannelThreshold\n",
    "        self.redChannelThreshold = redChannelThreshold\n",
    "        self.sobelKernelSize = sobelKernelSize\n",
    "        \n",
    "    def FindWindowLanesParameters(self, nWindows, minPix):\n",
    "        self.nWindows = nWindows\n",
    "        self.minPix = minPix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCameraCorrection(imagePath):\n",
    "    \n",
    "    objPoints = []\n",
    "    imgPoints = []\n",
    "    objP = np.zeros((9*6,3),np.float32)\n",
    "    objP[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "    #first find thee corners\n",
    "    for filename in imagePath:\n",
    "        img=mpimg.imread(filename)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "        if ret == True:\n",
    "            objPoints.append(objP)\n",
    "            imgPoints.append(corners)\n",
    "    \n",
    "    # Returns camera calibration\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objPoints, imgPoints, \n",
    "                                                       gray.shape[::-1], None, \n",
    "                                                       None)\n",
    "    \n",
    "    return mtx, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageLocation = glob.glob('camera_cal/*.jpg')\n",
    "\n",
    "# Calibrate camera and return calibration data\n",
    "mtx, dist = GetCameraCorrection(imageLocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter image to get rough lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetBinaryImage(image, mtx, dst):\n",
    "    undistortedImage = cv2.undistort(image, mtx, dst, None, mtx)\n",
    "    sobelThreshold = parameters.sobelThreshold\n",
    "    sChannelThreshold = parameters.sChannelThreshold\n",
    "    redChannelThreshold = parameters.redChannelThreshold\n",
    "    sobelKernelSize = parameters.sobelKernelSize\n",
    "    redImage = undistortedImage[:,:,0]\n",
    "    hsvImage = cv2.cvtColor(undistortedImage, cv2.COLOR_RGB2HSV).astype(np.float)\n",
    "    # Convert to HLS colorspace\n",
    "    hlsImage = cv2.cvtColor(undistortedImage, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    sImage = hlsImage[:,:,2]\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    vImage = hsvImage[:,:,2]\n",
    "    \n",
    "    \n",
    "    #Applying Sobel Filter, creaating Binary image\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize = sobelKernelSize) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobelx = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    sxbinary = np.zeros_like(scaled_sobelx)\n",
    "    sxbinary[(scaled_sobelx >= sobelThreshold[0]) & (scaled_sobelx <= sobelThreshold[1])] = 1\n",
    "   \n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize = sobelKernelSize) # Take the derivative in x\n",
    "    abs_sobely = np.absolute(sobely) # Absolute y derivative to accentuate lines away from horizontal\n",
    "    scaled_sobely = np.uint8(255*abs_sobely/np.max(abs_sobely))\n",
    "    sybinary = np.zeros_like(scaled_sobely)\n",
    "    sybinary[(scaled_sobely >= sobelThreshold[0]) & (scaled_sobely <= sobelThreshold[1])] = 1\n",
    "    #Applying thresholding to S channel\n",
    "    sBinary = np.zeros_like(sImage)\n",
    "    sBinary[(sImage >= sChannelThreshold[0]) & (sImage <= sChannelThreshold[1])] = 1\n",
    "    \n",
    "    #Applying thresold Red channel\n",
    "    rBinary = np.zeros_like(redImage)\n",
    "    rBinary[(redImage>=redChannelThreshold[0]) & (redImage<=redChannelThreshold[1])] = 1\n",
    "    \n",
    "    #Applying thresold Red channel\n",
    "    vBinary = np.zeros_like(vImage)\n",
    "    vBinary[(vImage>=230) & (vImage<=255)] = 1\n",
    "    \n",
    "    #Stacking for debugging\n",
    "    #combinedBinary = np.dstack(( np.zeros_like(sxbinary), sxbinary, sBinary)) * 255\n",
    "    \n",
    "    # Combine the  binary thresholds\n",
    "    combinedBinary = np.zeros_like(sxbinary)\n",
    "    combinedBinary[(vBinary == 1) | (sxbinary == 1) | (rBinary == 1)] = 1\n",
    "    #combinedBinary[(vBinary == 1)] = 1\n",
    "    \n",
    "    return combinedBinary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert image to to down perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PerspectiveTransform(image, mtx, dst):\n",
    "    #Perspective transform to obtain a top down image\n",
    "    \n",
    "    #First obtain binary image\n",
    "    binaryImage = GetBinaryImage(image, mtx, dst)\n",
    "    \n",
    "    #get image size\n",
    "    imageSize = (binaryImage.shape[1], binaryImage.shape[0])\n",
    "    \n",
    "    #get 4 reference points\n",
    "    source = np.float32([[585,455],[705,455],[1130,720],[190,720]])\n",
    "    \n",
    "    #4 points from the image\n",
    "    offset = 200 # offset for dst points\n",
    "    dst = np.float32([\n",
    "    [offset, 0],\n",
    "    [imageSize[0]-offset, 0],\n",
    "    [imageSize[0]-offset, imageSize[1]], \n",
    "    [offset, imageSize[1]]\n",
    "])\n",
    "    \n",
    "    # Use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "    M = cv2.getPerspectiveTransform(source, dst)\n",
    "    \n",
    "    # Use cv2.warpPerspective() to warp the image to a top-down view\n",
    "    topDown = cv2.warpPerspective(binaryImage, M, imageSize)\n",
    "\n",
    "    return topDown, M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the lane lines on the perspective image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conversions in x and y from pixels space to meters\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "def findLines(image, nwindows=9, margin=110, minpix=50):\n",
    "    \"\"\"\n",
    "    Find the polynomial representation of the lines in the `image` using:\n",
    "    - `nwindows` as the number of windows.\n",
    "    - `margin` as the windows margin.\n",
    "    - `minpix` as minimum number of pixes found to recenter the window.\n",
    "    - `ym_per_pix` meters per pixel on Y.\n",
    "    - `xm_per_pix` meters per pixels on X.\n",
    "    \n",
    "    Returns (left_fit, right_fit, left_lane_inds, right_lane_inds, out_img, nonzerox, nonzeroy)\n",
    "    \"\"\"    \n",
    "    # Make a binary and transform image\n",
    "    binary_warped, M = PerspectiveTransform(image, mtx, dist)\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "    \n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit_m = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_m = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    \n",
    "    return (left_fit, right_fit, left_fit_m, right_fit_m, left_lane_inds, right_lane_inds, out_img, nonzerox, nonzeroy, M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculateCurvature(yRange, left_fit_cr):\n",
    "    \"\"\"\n",
    "    Returns the curvature of the polynomial `fit` on the y range `yRange`.\n",
    "    \"\"\"\n",
    "    \n",
    "    return ((1 + (2*left_fit_cr[0]*yRange*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "\n",
    "def drawLine(img, left_fit, right_fit, M):\n",
    "    \"\"\"\n",
    "    Draw the lane lines on the image `img` using the poly `left_fit` and `right_fit`.\n",
    "    \"\"\"\n",
    "    yMax = img.shape[0]\n",
    "    ploty = np.linspace(0, yMax - 1, yMax)\n",
    "    color_warp = np.zeros_like(img).astype(np.uint8)\n",
    "    \n",
    "    # Calculate points.\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, np.linalg.inv(M), (img.shape[1], img.shape[0])) \n",
    "    return cv2.addWeighted(img, 1, newwarp, 0.3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video Advanced_Lane_Detection.mp4\n",
      "[MoviePy] Writing video Advanced_Lane_Detection.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [05:22<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: Advanced_Lane_Detection.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "class Lane():\n",
    "    def __init__(self):\n",
    "        self.left_fit = None\n",
    "        self.right_fit = None\n",
    "        self.left_fit_m = None\n",
    "        self.right_fit_m = None\n",
    "        self.leftCurvature = None\n",
    "        self.rightCurvature = None\n",
    "\n",
    "def calculateLanes(img):\n",
    "    \"\"\"\n",
    "    Calculates the lane on image `img`.\n",
    "    \"\"\"\n",
    "    left_fit, right_fit, left_fit_m, right_fit_m, _, _, _, _, _,M = findLines(img)\n",
    "    # Calculate curvature\n",
    "    yRange = 719\n",
    "    leftCurvature = calculateCurvature(yRange, left_fit_m) \n",
    "    rightCurvature = calculateCurvature(yRange, right_fit_m)\n",
    "    \n",
    "    # Calculate vehicle center\n",
    "    xMax = img.shape[1]*xm_per_pix\n",
    "    yMax = img.shape[0]*ym_per_pix\n",
    "    vehicleCenter = xMax / 2\n",
    "    lineLeft = left_fit_m[0]*yMax**2 + left_fit_m[1]*yMax + left_fit_m[2]\n",
    "    lineRight = right_fit_m[0]*yMax**2 + right_fit_m[1]*yMax + right_fit_m[2]\n",
    "    lineMiddle = lineLeft + (lineRight - lineLeft)/2\n",
    "    diffFromVehicle = lineMiddle - vehicleCenter\n",
    "    \n",
    "    return (left_fit, right_fit, left_fit_m, right_fit_m, leftCurvature, rightCurvature, diffFromVehicle, M)\n",
    "\n",
    "def displayLanes(img, left_fit, right_fit, left_fit_m, right_fit_m, leftCurvature, rightCurvature, diffFromVehicle,M):\n",
    "    \"\"\"\n",
    "    Display the lanes information on the image.\n",
    "    \"\"\"\n",
    "    output = drawLine(img, left_fit, right_fit,M)\n",
    "    \n",
    "    if diffFromVehicle > 0:\n",
    "        message = '{:.2f} m right'.format(diffFromVehicle)\n",
    "    else:\n",
    "        message = '{:.2f} m left'.format(-diffFromVehicle)\n",
    "    \n",
    "    # Draw info\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontColor = (255, 255, 255)\n",
    "    cv2.putText(output, 'Left curvature: {:.0f} m'.format(leftCurvature), (50, 50), font, 1, fontColor, 2)\n",
    "    cv2.putText(output, 'Right curvature: {:.0f} m'.format(rightCurvature), (50, 120), font, 1, fontColor, 2)\n",
    "    cv2.putText(output, 'Vehicle is {} of center'.format(message), (50, 190), font, 1, fontColor, 2)\n",
    "    return output\n",
    "    \n",
    "def videoPipeline(inputVideo, outputVideo):\n",
    "    \"\"\"\n",
    "    Process the `inputVideo` frame by frame to find the lane lines, draw curvarute and vehicle position information and\n",
    "    generate `outputVideo`\n",
    "    \"\"\"\n",
    "    myclip = VideoFileClip(inputVideo)\n",
    "    parameters = Parameters()\n",
    "    parameters.BinaryImageThreshold((70,160), (110,140), (215,255), 3)\n",
    "    parameters.FindWindowLanesParameters(20,50)\n",
    "    leftLane = Lane()\n",
    "    rightLane = Lane()\n",
    "    \n",
    "    def processImage(img):\n",
    "        left_fit, right_fit, left_fit_m, right_fit_m, leftCurvature, rightCurvature, diffFromVehicle,M = calculateLanes(img)\n",
    "        if leftCurvature > 10000:\n",
    "            left_fit = leftLane.left_fit\n",
    "            left_fit_m = leftLane.left_fit_m\n",
    "            leftCurvature = leftLane.leftCurvature\n",
    "        else:\n",
    "            leftLane.left_fit = left_fit\n",
    "            leftLane.left_fit_m = left_fit_m\n",
    "            leftLane.leftCurvature = leftCurvature\n",
    "        \n",
    "        if rightCurvature > 10000:\n",
    "            right_fit = rightLane.right_fit\n",
    "            right_fit_m = rightLane.right_fit_m\n",
    "            rightCurvature = rightLane.rightCurvature\n",
    "        else:\n",
    "            rightLane.right_fit = right_fit\n",
    "            rightLane.right_fit_m = right_fit_m\n",
    "            rightLane.rightCurvature = rightCurvature\n",
    "            \n",
    "        return displayLanes(img, left_fit, right_fit, left_fit_m, right_fit_m, leftCurvature, rightCurvature, diffFromVehicle,M)\n",
    "\n",
    "    clip = myclip.fl_image(processImage)\n",
    "    clip.write_videofile(outputVideo, audio=False)\n",
    "\n",
    "# Project video\n",
    "videoPipeline('project_video.mp4', 'Advanced_Lane_Detection.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
